{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockbuster\n",
    "\n",
    "\n",
    "### add gif if needed\n",
    "\n",
    "# Table of Content\n",
    "\n",
    "1. Introduction\n",
    "    * Business Overview of the Movie Industry\n",
    "    * Business Understanding\n",
    "    * Business Question/Hypothesis\n",
    " \n",
    " \n",
    "2. Data Exploration/Analysis\n",
    "    * Data Understanding\n",
    "    * Data Analysis\n",
    "  \n",
    "  \n",
    "3. Hypothesis Testing\n",
    "    * Statistical Inference\n",
    " \n",
    " \n",
    "3. End\n",
    "    * Recommendations\n",
    "    * Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook was collaborated by all team mates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Overview of the US Movie Industry\n",
    "Little info about the movie industry, profits, some statistics basically. That will be helpful in forming our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem/ What the client wants\n",
    "Computing Vision (a made-up company for the purposes of this project) sees all the big companies creating original video content and they want to get in on the fun. They have decided to create a new movie studio, but they donâ€™t have much background in creating movies. You are charged with exploring what types of films are currently doing the best at the box office using different samples of available data. You then will translate those findings into actionable insights that the head of Computing Vision's new movie studio can use to help decide what type of films to create."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Questions\n",
    "\n",
    "## Buisness Question 1:\n",
    "- Which combination of factors influence the success of a movie in terms of the best ROI?\n",
    "  ** correlation among the factors- profit, genre, runtime, ratings, etc\n",
    " \n",
    "## Buisness Question 2:\n",
    "- production budget\n",
    "_\n",
    "***\n",
    "\n",
    "## Buisness Question 3:\n",
    "- Movie studios that produces a lot of action movies have the best ROI\n",
    "\n",
    "\n",
    "###  happy to hear what others think in terms of what we should be looking out for in the data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration/ Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sqlite3 #import sqlite 3 module\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the current directory to help with easy read\n",
    "#NB: Pandas read data from the current directory and may issue an error if the data is not located in the current dir\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSv and tsv files into the instance\n",
    "DATA_DIR = \"../../Data/original_data/\"\n",
    "#DATA_DIR = \"C:/Users\\Raddodanquah/Documents/Flatiron/group-4-0206_3-4/Data/original_data/\"\n",
    "FILE_NAME1 = \"bom.movie_gross.csv\"\n",
    "FILE_NAME2 = \"tmdb.movies.csv\"\n",
    "FILE_NAME3 = \"tn.movie_budgets.csv\"\n",
    "FILE_NAME4 = \"rt_reviews.csv\"\n",
    "FILE_NAME5 = \"rt_movie_info.csv\"\n",
    "bom_movies = pd.read_csv(f\"{DATA_DIR}{FILE_NAME1}\")\n",
    "tmd_movies= pd.read_csv(f\"{DATA_DIR}{FILE_NAME2}\")\n",
    "tn_movies =pd.read_csv(f\"{DATA_DIR}{FILE_NAME3}\")\n",
    "rt_reviews =pd.read_csv(f\"{DATA_DIR}{FILE_NAME4}\", sep='\\t', engine='python' )\n",
    "rt_movie_info =pd.read_csv(f\"{DATA_DIR}{FILE_NAME5}\", sep='\\t', engine='python' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the db file\n",
    "# NB: Just like the other reads, make sure the db connection is done in the right dir to avoid errors/empty tables\n",
    "\n",
    "dbfile =\"../../Data/im_combined.db\"\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(dbfile)\n",
    "\n",
    "# creating cursor\n",
    "cur = con.cursor()\n",
    "\n",
    "# reading all table names\n",
    "#table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "# here is you table list\n",
    "#print(table_list)\n",
    "\n",
    "# Be sure to close the connection\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the data - A focus on the columns and the data type respectively\n",
    "\n",
    "- bom_movies details\n",
    " * Data file has 3387 rows with 5 columns\n",
    "   * The columns are : title', 'studio', 'domestic_gross', 'foreign_gross', 'year'\n",
    " * There are missing data that we need to investigate and determine the best way to resolve this\n",
    " * Year column data type needs to be changed from int to datetime\n",
    " * foreign_gross data type needs to be changed to int and so is the domestic_gross\n",
    " * Convert the domestic_gross and foreign_gross into a more easy way to read, divide by 1,000,000\n",
    " *  <span style=\"color:red\"> May need to remove the studio column- early to decide  </style>\n",
    " * <span style=\"color:green\"> We will assume that the domestic and foreign gross revenue are in us dollars </style>\n",
    "\n",
    " \n",
    " \n",
    " - tmd_movies details\n",
    "  * Data file has 26517 rows with 10 columns\n",
    "    * The columns are : 'Unnamed: 0', 'genre_ids', 'id', 'original_language', 'original_title','popularity', 'release_date',    'title', 'vote_average', 'vote_count'\n",
    "  * There are no missing data - whewww!!(just kidding)\n",
    "  * Release date column data type needs to be changed to datetime\n",
    "  *  <span style=\"color:red\"> May need to remove some colums: unnamed, genre_ids?(maybe), original_title is redundant with title and original languae column- has 1 unique data type  </style>\n",
    "  * <span style=\"color:green\"> We will assume that with popularity, the bigger the number, the higher the popularity </style>\n",
    " \n",
    " \n",
    "  - tn_movie_budget details\n",
    "   * Data file has 5782 rows with 6 columns\n",
    "    * The columns are : id', 'release_date', 'movie', 'production_budget', 'domestic_gross',\n",
    "       'worldwide_gross'\n",
    "   * There are no missing data - whewww!!\n",
    "   * release_date column data type needs to be changed to datetime\n",
    "   * Production_budget, domestic_gross and worldwide_gross should all be float with easy to read data values\n",
    "  \n",
    " \n",
    " - rt_movie_info details\n",
    "  * Data file has 1560 rows with 12 columns\n",
    "    * The columns are : 'id', 'synopsis', 'rating', 'genre', 'director', 'writer',\n",
    "       'theater_date', 'dvd_date', 'currency', 'box_office', 'runtime',\n",
    "       'studio'\n",
    "   * Other than Id column, the rest of the data has missing values\n",
    "     * The columns that have more than 2/3rd of missing values can be dropped\n",
    "       * Studio\n",
    "       * box_office\n",
    "       * currency\n",
    "   * runtime column data type needs to be changed to datetime\n",
    "   * rating columns to integer\n",
    "   * Production_budget, domestic_gross and worldwide_gross should all be float with easy to read data values\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing and feature selection \n",
    "- Data cleansing is the process of ensuring that that the data is in its ready state to be used for analysis.\n",
    "  * Focus will be setting the columns to the right data type, dealing with null values and dropping for the starter, columns deemed not \"relevant\" to this analysis\n",
    "  \n",
    "- Feature Selection using domain/business knowledge as opposed to using rigourous statistical method of selecton such as LASSO, Ridge, etc\n",
    "  * Further drop columns that will not be anyway useful to the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for Bom Movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (3387,5)\n",
    "- Removing null values and changing data type\n",
    "- Key action\n",
    "  * foreign_gross has about 40% missing value, so we drop the column\n",
    "  * The other columns have insignficant amount of missing value so we removed the rows\n",
    "  \n",
    "## Final data shape (row by col) --- (3356,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movies.isnull().sum() # checking for missing/null/na values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bom_movies.drop([\"foreign_gross\"], axis = 1, inplace = True) # dropped foreign_gross from the data\n",
    "bom_movies.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies= bom_movies.dropna(axis = 0, how ='any') # dropped all othe na/null/missing value from the remaining data\n",
    "new_bom_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_bom_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "new_bom_movies.image = plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies['domestic_gross']= new_bom_movies['domestic_gross'].astype(int) # Changing data type to Int\n",
    "#new_bom_movies['year']= pd.to_datetime(bom_movies.year, format='%Y%') # Changing data type to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies.info() # making sure the data is in the form that we want it to be, cols, data types, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Data Cleansing for tmd movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (26517,10)\n",
    "- This dataset has no missing value as shown in the graph\n",
    "- Need to drop some columns that are not relevant to our business case\n",
    "   * Unnamed\n",
    "   * genre_ids\n",
    "   * original_title is redundant with title\n",
    "- Change column data type\n",
    "   * release_date to date data type\n",
    "   \n",
    "## Final data shape (row by col) --- (26517,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values, which means less work in that regard :)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=tmd_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "tmd_movies_image= plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_movies.reindex()\n",
    "new_tmd_movies= tmd_movies.drop(tmd_movies.columns[[0, 1,4]], axis=1)\n",
    "new_tmd_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmd_movies.info() # checking to see the data type and what needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data type to date\n",
    "new_tmd_movies[' release_date']= pd.to_datetime(new_tmd_movies. release_date, format= '%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmd_movies.info() # release date has the date datat type now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for tn movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (5782,6)\n",
    "- This dataset has no missing value as shown in the graph\n",
    "- Drop the wordwide gross as the focus of this business case will be on domestic gross revenue\n",
    "- Change column data type\n",
    "   * release_date should be consistent withthe format and type like the other tables\n",
    "   * domestic_gross and production budget format should be the same in other tables, no dollar sign, no commas\n",
    "   \n",
    "## Final data shape (row by col) --- (5782,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=tn_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_movies.head() # preview the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies= tn_movies.drop(tn_movies.columns[5], axis=1)\n",
    "new_tn_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting production_budget and domestic_gross columns into int and a consistent format just like others with no comma or $\n",
    "new_tn_movies['production_budget']= new_tn_movies['production_budget'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "new_tn_movies['domestic_gross']= new_tn_movies['domestic_gross'].str.replace(',', '').str.replace('$', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting error converting,will revert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# changing to a consistent date type \n",
    "new_tn_movies['release_date']= pd.to_datetime(new_tn_movies['release_date'], ,errors = 'coerce',format = '%Y-%m-%d').dt.strftime(\"%Y%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for rt movie info data\n",
    "\n",
    "## Initial data shape (row by col) --- (1560,12)\n",
    "- This dataset hassome missing values, some as high as about 2/3rd missing values\n",
    "- Columns dropped\n",
    "   * studio, currency, and box_office will be dropped due to a significant amount of missing data\n",
    "   * synopsis which is just a brief summary of the movie will not be in scope for our work\n",
    "   \n",
    "- Create a new column (runtime_mins) and make the data type int\n",
    "\n",
    "## Final data shape (row by col) --- (1032,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info.head() # display the first few roles for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values [ cols with true or a mixture of orange and blue color]\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the already mentioned columns [studio,box_office,currency](they have significant high volume of missing data), \n",
    "# drop [synopsis,theater_date,dvd_date]-- nto in scope for our business case\n",
    "# create a new df for the in scope features\n",
    "new_rt_movie_info= rt_movie_info[['id','rating', 'genre', 'director', 'writer','runtime']] # cols interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value for the new df\n",
    "# As you can see, there are no missing values [ cols with true or a mixture of orange and blue color]\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n",
    "\n",
    "# for now we will keep the data as it is without removing any missing data. We can always come back and \n",
    "## take them out if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info() # checking to see the data type for the runtime col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split team column into two columns\n",
    "new_rt_movie_info[['runtime/mins', 'minutes']] = new_rt_movie_info['runtime'].str.split(' ', 1, expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info= new_rt_movie_info.dropna(axis = 0, how ='any') # dropped all othe na/null/missing value from the remaining data\n",
    "new_rt_movie_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value for the new df\n",
    "# As you can see, there are no missing values now\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n",
    "\n",
    "# for now we will keep the data as it is without removing any missing data. We can always come back and \n",
    "## take them out if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info['runtime/mins']= new_rt_movie_info['runtime/mins'].astype(int) # Changing data type to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take out the other 2 unwanted cols, runtime & minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info= rt_movie_info[['id','rating', 'genre', 'director', 'writer','runtime/mins']] # cols interested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So far with the flat files we have in good shape are:\n",
    "## new_bom_movies\n",
    "## new_rt_movie_info\n",
    "## new_tmd_movies\n",
    "## new_tn_movies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull two tables from the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the db file\n",
    "# NB: Just like the other reads, make sure the db connection is done in the right dir to avoid errors/empty tables\n",
    "\n",
    "dbfile =\"C:/Users\\Raddodanquah/Documents/Flatiron/Final_project_Group4/Data/im.db\"\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(dbfile)\n",
    "\n",
    "# creating cursor\n",
    "cur = con.cursor()\n",
    "\n",
    "# reading all table names\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "# here is you table list\n",
    "print(table_list)\n",
    "\n",
    "# Be sure to close the connection\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is from 2010 and above because we dont financials for years less than 2010\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT a.movie_id,a.primary_title,a.start_year,a.runtime_minutes,a.genres, b.averagerating,b.numvotes\n",
    "FROM movie_basics a\n",
    "JOIN movie_ratings b\n",
    "USING (movie_id)\n",
    "where start_year >=2010\n",
    ";\"\"\"\n",
    "db_database = pd.read_sql(q, con)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blockbuster\n",
    "\n",
    "\n",
    "### add gif if needed\n",
    "\n",
    "# Table of Content\n",
    "\n",
    "1. Introduction\n",
    "    * Business Overview of the Movie Industry\n",
    "    * Business Understanding\n",
    "    * Business Question/Hypothesis\n",
    " \n",
    " \n",
    "2. Data Exploration/Analysis\n",
    "    * Data Understanding\n",
    "    * Data Analysis\n",
    "  \n",
    "  \n",
    "3. Hypothesis Testing\n",
    "    * Statistical Inference\n",
    " \n",
    " \n",
    "3. End\n",
    "    * Recommendations\n",
    "    * Next Steps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Overview of the US Movie Industry\n",
    "Little info about the movie industry, profits, some statistics basically. That will be helpful in forming our hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem/ What the client wants\n",
    "Computing Vision (a made-up company for the purposes of this project) sees all the big companies creating original video content and they want to get in on the fun. They have decided to create a new movie studio, but they donâ€™t have much background in creating movies. You are charged with exploring what types of films are currently doing the best at the box office using different samples of available data. You then will translate those findings into actionable insights that the head of Computing Vision's new movie studio can use to help decide what type of films to create."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Questions\n",
    "1. What type of films are doing the best at the box office\n",
    "- Are high budget movies yielding higher profits:\n",
    "- What genre of movies will provide the business with the best ROI?\n",
    "- Are there any correlation between movie popularity and profit?\n",
    "- Which combination of features will influence profit\n",
    "  * Genre\n",
    "  * Ratings\n",
    "  * Duration\n",
    "  * Time of release\n",
    "  * Star Power?\n",
    "  * \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration/ Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries import\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sqlite3 #import sqlite 3 module\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the current directory to help with easy read\n",
    "#NB: Pandas read data from the current directory and may issue an error if the data is not located in the current dir\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSv and tsv files into the instance\n",
    "\n",
    "DATA_DIR = \"C:/Users\\Raddodanquah/Documents/Flatiron/Final_project_Group4/Data/\"\n",
    "FILE_NAME1 = \"bom.movie_gross.csv\"\n",
    "FILE_NAME2 = \"tmdb.movies.csv\"\n",
    "FILE_NAME3 = \"tn.movie_budgets.csv\"\n",
    "FILE_NAME4 = \"rt.reviews.tsv\"\n",
    "FILE_NAME5 = \"rt.movie_info.tsv\"\n",
    "bom_movies = pd.read_csv(f\"{DATA_DIR}{FILE_NAME1}\")\n",
    "tmd_movies= pd.read_csv(f\"{DATA_DIR}{FILE_NAME2}\")\n",
    "tn_movies =pd.read_csv(f\"{DATA_DIR}{FILE_NAME3}\")\n",
    "rt_reviews =pd.read_csv(f\"{DATA_DIR}{FILE_NAME4}\", sep='\\t', engine='python' )\n",
    "rt_movie_info =pd.read_csv(f\"{DATA_DIR}{FILE_NAME5}\", sep='\\t', engine='python' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the db file\n",
    "# NB: Just like the other reads, make sure the db connection is done in the right dir to avoid errors/empty tables\n",
    "\n",
    "dbfile =\"C:/Users\\Raddodanquah/Documents/Flatiron/Final_project_Group4/Data/im.db\"\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(dbfile)\n",
    "\n",
    "# creating cursor\n",
    "cur = con.cursor()\n",
    "\n",
    "# reading all table names\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "# here is you table list\n",
    "print(table_list)\n",
    "\n",
    "# Be sure to close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the data - A focus on the columns and the data type respectively\n",
    "\n",
    "- bom_movies details\n",
    " * Data file has 3387 rows with 5 columns\n",
    "   * The columns are : title', 'studio', 'domestic_gross', 'foreign_gross', 'year'\n",
    " * There are missing data that we need to investigate and determine the best way to resolve this\n",
    " * Year column data type needs to be changed from int to datetime\n",
    " * foreign_gross data type needs to be changed to int and so is the domestic_gross\n",
    " * Convert the domestic_gross and foreign_gross into a more easy way to read, divide by 1,000,000\n",
    " *  <span style=\"color:red\"> May need to remove the studio column- early to decide  </style>\n",
    " * <span style=\"color:green\"> We will assume that the domestic and foreign gross revenue are in us dollars </style>\n",
    "\n",
    " \n",
    " \n",
    " - tmd_movies details\n",
    "  * Data file has 26517 rows with 10 columns\n",
    "    * The columns are : 'Unnamed: 0', 'genre_ids', 'id', 'original_language', 'original_title','popularity', 'release_date',    'title', 'vote_average', 'vote_count'\n",
    "  * There are no missing data - whewww!!(just kidding)\n",
    "  * Release date column data type needs to be changed to datetime\n",
    "  *  <span style=\"color:red\"> May need to remove some colums: unnamed, genre_ids?(maybe), original_title is redundant with title and original languae column- has 1 unique data type  </style>\n",
    "  * <span style=\"color:green\"> We will assume that with popularity, the bigger the number, the higher the popularity </style>\n",
    " \n",
    " \n",
    "  - tn_movie_budget details\n",
    "   * Data file has 5782 rows with 6 columns\n",
    "    * The columns are : id', 'release_date', 'movie', 'production_budget', 'domestic_gross',\n",
    "       'worldwide_gross'\n",
    "   * There are no missing data - whewww!!\n",
    "   * release_date column data type needs to be changed to datetime\n",
    "   * Production_budget, domestic_gross and worldwide_gross should all be float with easy to read data values\n",
    "  \n",
    " \n",
    " - rt_movie_info details\n",
    "  * Data file has 1560 rows with 12 columns\n",
    "    * The columns are : 'id', 'synopsis', 'rating', 'genre', 'director', 'writer',\n",
    "       'theater_date', 'dvd_date', 'currency', 'box_office', 'runtime',\n",
    "       'studio'\n",
    "   * Other than Id column, the rest of the data has missing values\n",
    "     * The columns that have more than 2/3rd of missing values can be dropped\n",
    "       * Studio\n",
    "       * box_office\n",
    "       * currency\n",
    "   * runtime column data type needs to be changed to datetime\n",
    "   * rating columns to integer\n",
    "   * Production_budget, domestic_gross and worldwide_gross should all be float with easy to read data values\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing and feature selection \n",
    "- Data cleansing is the process of ensuring that that the data is in its ready state to be used for analysis.\n",
    "  * Focus will be setting the columns to the right data type, dealing with null values and dropping for the starter, columns deemed not \"relevant\" to this analysis\n",
    "  \n",
    "- Feature Selection using domain/business knowledge as opposed to using rigourous statistical method of selecton such as LASSO, Ridge, etc\n",
    "  * Further drop columns that will not be anyway useful to the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for Bom Movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (3387,5)\n",
    "- Removing null values and changing data type\n",
    "- Key action\n",
    "  * foreign_gross has about 40% missing value, so we drop the column\n",
    "  * The other columns have insignficant amount of missing value so we removed the rows\n",
    "  \n",
    "## Final data shape (row by col) --- (3356,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bom_movies.isnull().sum() # checking for missing/null/na values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bom_movies.drop([\"foreign_gross\"], axis = 1, inplace = True) # dropped foreign_gross from the data\n",
    "bom_movies.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies= bom_movies.dropna(axis = 0, how ='any') # dropped all othe na/null/missing value from the remaining data\n",
    "new_bom_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_bom_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies['domestic_gross']= new_bom_movies['domestic_gross'].astype(int) # Changing data type to Int\n",
    "new_bom_movies['year']= pd.to_datetime(bom_movies.year, format='%Y%') # Changing data type to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bom_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Data Cleansing for tmd movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (26517,10)\n",
    "- This dataset has no missing value as shown in the graph\n",
    "- Need to drop some columns that are not relevant to our business case\n",
    "   * Unnamed\n",
    "   * genre_ids\n",
    "   * original_title is redundant with title\n",
    "- Change column data type\n",
    "   * release_date to date data type\n",
    "   \n",
    "## Final data shape (row by col) --- (26517,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=tmd_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmd_movies.reindex()\n",
    "new_tmd_movies= tmd_movies.drop(tmd_movies.columns[[0, 1,4]], axis=1)\n",
    "new_tmd_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmd_movies.info() # checking to see the data type and what needs to be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing data type to date\n",
    "new_tmd_movies[' release_date']= pd.to_datetime(new_tmd_movies. release_date, format= '%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tmd_movies.info() # release date has the date datat type now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for tn movie data\n",
    "\n",
    "## Initial data shape (row by col) --- (5782,6)\n",
    "- This dataset has no missing value as shown in the graph\n",
    "- Drop the wordwide gross as the focus of this business case will be on domestic gross revenue\n",
    "- Change column data type\n",
    "   * release_date should be consistent withthe format and type like the other tables\n",
    "   * domestic_gross and production budget format should be the same in other tables, no dollar sign, no commas\n",
    "   \n",
    "## Final data shape (row by col) --- (5782,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=tn_movies.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_movies.head() # preview the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies= tn_movies.drop(tn_movies.columns[5], axis=1)\n",
    "new_tn_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting production_budget and domestic_gross columns into int and a consistent format just like others with no comma or $\n",
    "new_tn_movies['production_budget']= new_tn_movies['production_budget'].str.replace(',', '').str.replace('$', '').astype(int)\n",
    "new_tn_movies['domestic_gross']= new_tn_movies['domestic_gross'].str.replace(',', '').str.replace('$', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tn_movies.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting error converting,will revert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# changing to a consistent date type \n",
    "new_tn_movies['release_date']= pd.to_datetime(new_tn_movies['release_date'], ,errors = 'coerce',format = '%Y-%m-%d').dt.strftime(\"%Y%m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing for rt movie info data\n",
    "\n",
    "## Initial data shape (row by col) --- (1560,12)\n",
    "- This dataset hassome missing values, some as high as about 2/3rd missing values\n",
    "- Columns dropped\n",
    "   * studio, currency, and box_office will be dropped due to a significant amount of missing data\n",
    "   * synopsis which is just a brief summary of the movie will not be in scope for our work\n",
    "   \n",
    "- Create a new column (runtime_mins) and make the data type int\n",
    "\n",
    "## Final data shape (row by col) --- (1032,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info.head() # display the first few roles for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value\n",
    "# As you can see, there are no missing values [ cols with true or a mixture of orange and blue color]\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the already mentioned columns [studio,box_office,currency](they have significant high volume of missing data), \n",
    "# drop [synopsis,theater_date,dvd_date]-- nto in scope for our business case\n",
    "# create a new df for the in scope features\n",
    "new_rt_movie_info= rt_movie_info[['id','rating', 'genre', 'director', 'writer','runtime']] # cols interested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value for the new df\n",
    "# As you can see, there are no missing values [ cols with true or a mixture of orange and blue color]\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n",
    "\n",
    "# for now we will keep the data as it is without removing any missing data. We can always come back and \n",
    "## take them out if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info() # checking to see the data type for the runtime col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split team column into two columns\n",
    "new_rt_movie_info[['runtime/mins', 'minutes']] = new_rt_movie_info['runtime'].str.split(' ', 1, expand=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info= new_rt_movie_info.dropna(axis = 0, how ='any') # dropped all othe na/null/missing value from the remaining data\n",
    "new_rt_movie_info.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing data for missing value for the new df\n",
    "# As you can see, there are no missing values now\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.displot(\n",
    "    data=new_rt_movie_info.isnull().melt(value_name=\"missing\"),\n",
    "    y=\"variable\",\n",
    "    hue=\"missing\",\n",
    "    multiple=\"fill\",\n",
    "    aspect=1.25\n",
    ")\n",
    "plt.savefig(\"visualizing_missing_data_with_barplot_Seaborn_distplot.png\", dpi=100)\n",
    "\n",
    "# for now we will keep the data as it is without removing any missing data. We can always come back and \n",
    "## take them out if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info['runtime/mins']= new_rt_movie_info['runtime/mins'].astype(int) # Changing data type to Int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take out the other 2 unwanted cols, runtime & minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rt_movie_info= rt_movie_info[['id','rating', 'genre', 'director', 'writer','runtime/mins']] # cols interested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So far with the flat files we have in good shape are:\n",
    "## new_bom_movies\n",
    "## new_rt_movie_info\n",
    "## new_tmd_movies\n",
    "## new_tn_movies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull two tables from the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('IMDB_movie_basics',), ('IMDB_directors',), ('IMDB_known_for',), ('IMDB_movie_akas',), ('IMDB_movie_ratings',), ('IMDB_persons',), ('IMDB_principals',), ('IMDB_writers',), ('BOM_movie_gross',), ('RT_movie_reviews',), ('TMDB_movie_genres',), ('TN_movie_budgets',), ('TN_movie_budgets_formatted',), ('VIEW_movie_budgets',), ('RT_movie_info',)]\n"
     ]
    }
   ],
   "source": [
    "# Connecting to the db file\n",
    "# NB: Just like the other reads, make sure the db connection is done in the right dir to avoid errors/empty tables\n",
    "\n",
    "dbfile =\"../../Data/im_combined.db\"\n",
    "# Create a SQL connection to our SQLite database\n",
    "#conn = sqlite3.connect(dbfile)\n",
    "\n",
    "# creating cursor\n",
    "#cur = conn.cursor()\n",
    "\n",
    "# reading all table names\n",
    "table_list = [a for a in cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table'\")]\n",
    "# here is you table list\n",
    "print(table_list)\n",
    "\n",
    "# Be sure to close the connection\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>studio</th>\n",
       "      <th>TNWorlwideGross</th>\n",
       "      <th>TNDomesticGross</th>\n",
       "      <th>ComputedForeignGross</th>\n",
       "      <th>TNBudget/Cost</th>\n",
       "      <th>Computed_Profit_Loss</th>\n",
       "      <th>year</th>\n",
       "      <th>release_date</th>\n",
       "      <th>Genres</th>\n",
       "      <th>AverageRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>Par.</td>\n",
       "      <td>108286422</td>\n",
       "      <td>72082999</td>\n",
       "      <td>36203423</td>\n",
       "      <td>5000000</td>\n",
       "      <td>103286422</td>\n",
       "      <td>2016</td>\n",
       "      <td>3/11/2016</td>\n",
       "      <td>Drama,Horror,Mystery</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Strong</td>\n",
       "      <td>WB</td>\n",
       "      <td>71118378</td>\n",
       "      <td>45819713</td>\n",
       "      <td>25298665</td>\n",
       "      <td>35000000</td>\n",
       "      <td>36118378</td>\n",
       "      <td>2018</td>\n",
       "      <td>1/19/2018</td>\n",
       "      <td>Action,Drama,History</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12 Years a Slave</td>\n",
       "      <td>FoxS</td>\n",
       "      <td>181025343</td>\n",
       "      <td>56671993</td>\n",
       "      <td>124353350</td>\n",
       "      <td>20000000</td>\n",
       "      <td>161025343</td>\n",
       "      <td>2013</td>\n",
       "      <td>10/18/2013</td>\n",
       "      <td>Biography,Drama,History</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>127 Hours</td>\n",
       "      <td>FoxS</td>\n",
       "      <td>60217171</td>\n",
       "      <td>18335230</td>\n",
       "      <td>41881941</td>\n",
       "      <td>18000000</td>\n",
       "      <td>42217171</td>\n",
       "      <td>2010</td>\n",
       "      <td>11/5/2010</td>\n",
       "      <td>Adventure,Biography,Drama</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13 Hours: The Secret Soldiers of Benghazi</td>\n",
       "      <td>Par.</td>\n",
       "      <td>69411370</td>\n",
       "      <td>52853219</td>\n",
       "      <td>16558151</td>\n",
       "      <td>50000000</td>\n",
       "      <td>19411370</td>\n",
       "      <td>2016</td>\n",
       "      <td>1/15/2016</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title studio  TNWorlwideGross  \\\n",
       "0                        10 Cloverfield Lane   Par.        108286422   \n",
       "1                                  12 Strong     WB         71118378   \n",
       "2                           12 Years a Slave   FoxS        181025343   \n",
       "3                                  127 Hours   FoxS         60217171   \n",
       "4  13 Hours: The Secret Soldiers of Benghazi   Par.         69411370   \n",
       "\n",
       "   TNDomesticGross  ComputedForeignGross  TNBudget/Cost  Computed_Profit_Loss  \\\n",
       "0         72082999              36203423        5000000             103286422   \n",
       "1         45819713              25298665       35000000              36118378   \n",
       "2         56671993             124353350       20000000             161025343   \n",
       "3         18335230              41881941       18000000              42217171   \n",
       "4         52853219              16558151       50000000              19411370   \n",
       "\n",
       "   year release_date                     Genres  AverageRating  \n",
       "0  2016    3/11/2016       Drama,Horror,Mystery            7.2  \n",
       "1  2018    1/19/2018       Action,Drama,History            6.6  \n",
       "2  2013   10/18/2013    Biography,Drama,History            8.1  \n",
       "3  2010    11/5/2010  Adventure,Biography,Drama            7.6  \n",
       "4  2016    1/15/2016                       None            NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect('../../Data/im_combined.db')\n",
    "\n",
    "SQLQuery_2 = \"\"\"\n",
    "Select\n",
    "a.*\n",
    ",(Select b.genres from IMDB_movie_basics b where b.primary_title = a.title) as Genres\n",
    ",(Select c1.average_rating from IMDB_movie_basics b1, IMDB_movie_ratings c1 where c1.movie_id = b1.movie_id and b1.primary_title = a.title) as AverageRating\n",
    "\n",
    "from VIEW_movie_budgets a\n",
    "\n",
    "\n",
    ";\"\"\"\n",
    "\n",
    "df = pd.read_sql(SQLQuery_2,conn)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1255, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT *\n",
    "from IMDB_movie_basics\n",
    ";\"\"\"\n",
    "df1= pd.read_sql(q, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is from 2010 and above because we dont financials for years less than 2010\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT a.movie_id,a.primary_title,a.start_year,a.runtime_minutes,a.genres, b.averagerating,b.numvotes\n",
    "FROM movie_basics a\n",
    "JOIN movie_ratings b\n",
    "USING (movie_id)\n",
    "where start_year >=2010\n",
    ";\"\"\"\n",
    "db_database = pd.read_sql(q, con)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
